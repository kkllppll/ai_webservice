# Комплексний аналіз настроїв тексту за допомогою ШІ

Цей проєкт - вебсервіс для багаторівневого аналізу тексту за допомогою сучасних моделей штучного інтелекту. Сервіс дозволяє аналізувати **тональність**, **токсичність**, **теми тексту**, а також **резюмувати** великі фрагменти і **зберігати історію запитів** користувача.

## Технології

- **Backend**: Python 3.11+, Flask
- **Frontend**: HTML5, CSS3, JavaScript
- **Моделі ШІ**: Hugging Face Transformers (XLM-RoBERTa), API GPT від OpenAI
- **База даних та автентифікація**: Firebase (Auth + Firestore)
- **Транскрипція аудіо**: OpenAI Whisper
- **Формати файлів**: `.txt`, `.csv`, `.docx`, `.json`, `.pdf`, `.mp3`, `.wav`, `.m4a`

## Функціональність

- Аналіз **тональності** (мультимовна підтримка)
- Визначення **токсичності**
- Визначення **тематик** (2–3 релевантні категорії)
- Генерація **резюме** з великих текстів (OpenAI API)
- **Розпізнавання аудіо** (Whisper)
- **Збереження історії запитів** для авторизованих користувачів
- Можливість **аналізу без реєстрації** (обмежено)
- Сучасний, плавний і зручний інтерфейс

## Використані моделі

- `cardiffnlp/twitter-xlm-roberta-base-sentiment`: для аналізу тональності та тем
- `textdetox/xlmr-large-toxicity-classifier-v2`: для виявлення токсичності
- `cardiffnlp/tweet-topic-21-multi`: для визначення тематики
- `openai/whisper`: для перетворення аудіо у текст
- `openai/gpt`: для генерації та резюмування тексту

##  Структура проєкту

```bash
project/
├── app/
│   ├── api/              # Маршрути Flask API: endpoints для аналізу, логіки обробки запитів
│   ├── models/           # Завантаження та збереження NLP-моделей
│   ├── services/         # Виклики моделей, агрегація результатів
│   ├── utils/            # Допоміжні функції (обробка тексту, форматування, тощо)
│   └── text_chunker.py   # Модуль для розбиття великих текстів на частини
├── frontend/
│   ├── static/           
│   │   ├── css/          # Стилі (оформлення інтерфейсу)
│   │   └── js/           # JavaScript логіка (UI, динаміка, запити до API)
│   └── templates/        # HTML-шаблони для Flask (головна, форма аналізу, тощо)
├── instance/             # Приватні конфігурації: Firebase, ключі, API secrets 
├── requirements.txt      # Список Python-залежностей проєкту
├── run.py                # Точка входу — запуск Flask-серверу
└── README.md             # Опис проєкту, інструкції запуску
```

## Як запустити цей проєкт у себе на комп’ютері


### 1. Клонуйте репозиторій
```bash
git clone https://github.com/2025-TV-z11/Sharabura_ED.git
cd Sharabura_ED
```

### 2. Створіть та активуйте віртуальне середовище
```bash
python -m venv venv
venv\Scripts\activate
```

### 3. Встановіть всі потрібні бібліотеки

```bash 
pip install -r requirements.txt
```

### 4. Налаштуйте секретні ключі
Створи у корені проєкту файл .env з таким вмістом:

```bash
OPENAI_API_KEY=твій_ключ_від_OpenAI
FIREBASE_CREDENTIALS=instance/nlp-project-ai-firebase-adminsdk-fbsvc-bf5453db79.json
```


OPENAI_API_KEY потрібен для роботи з OpenAI — він відповідає за генерацію резюме.

FIREBASE_CREDENTIALS — це шлях до файлу з ключем для Firebase (він лежить у папці instance/).

‼Важливо: файл з ключами не можна викладати у відкритий доступ!

### 5. Запустіть застосунок 

```bash
python run.py
```

### 6. Запустіть у браузері

```bash
http://127.0.0.1:5000
```
